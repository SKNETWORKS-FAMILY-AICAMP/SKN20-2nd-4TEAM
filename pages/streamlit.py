import json
import math
from pathlib import Path
from typing import Any, Dict, List, Optional, Sequence, Tuple

import joblib
import numpy as np
import pandas as pd
import streamlit as st
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline as SkPipeline
from sklearn.preprocessing import OneHotEncoder


ROOT_DIR = Path(__file__).resolve().parent.parent
MODEL_PATH = ROOT_DIR / 'model' / 'model_trained.pkl'
DATASET_PATH = ROOT_DIR / 'data' / 'dataset.csv'


def unwrap_estimator(estimator: Any) -> Any:
    """Follow best_estimator_ references until the fitted pipeline is reached."""

    current = estimator
    while hasattr(current, 'best_estimator_'):
        current = current.best_estimator_
    return current


def resolve_feature_names(estimator: Any) -> List[str]:
    names = getattr(estimator, 'feature_names_in_', None)
    if names is None:
        raise AttributeError('í•™ìŠµëœ íŒŒì´í”„ë¼ì¸ì—ì„œ feature_names_in_ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
    return [str(name) for name in list(names)]


def normalize_columns(selection: Any, feature_names: Sequence[str]) -> List[str]:
    if selection is None:
        return []
    if isinstance(selection, slice):
        return list(np.array(feature_names)[selection].tolist())
    if isinstance(selection, (list, tuple, set)):
        return [str(col) for col in selection]
    if isinstance(selection, np.ndarray):
        if selection.dtype == bool:
            return [name for name, flag in zip(feature_names, selection) if flag]
        return [feature_names[int(idx)] for idx in selection]
    if isinstance(selection, pd.Index):
        return selection.astype(str).tolist()
    return [str(selection)]


def extract_step(transformer: Any, target_cls: type) -> Optional[Any]:
    if isinstance(transformer, target_cls):
        return transformer
    if isinstance(transformer, SkPipeline):
        for step in transformer.named_steps.values():
            found = extract_step(step, target_cls)
            if found is not None:
                return found
    return None


def find_column_transformer(estimator: Any) -> Optional[ColumnTransformer]:
    if isinstance(estimator, ColumnTransformer):
        return estimator
    if isinstance(estimator, SkPipeline):
        for _, step in estimator.steps:
            found = find_column_transformer(step)
            if found is not None:
                return found
    return None


def clean_scalar(value: Any) -> Optional[Any]:
    if isinstance(value, np.generic):
        value = value.item()
    if isinstance(value, float) and math.isnan(value):
        return None
    return value


def compute_feature_modes(
    dataset: pd.DataFrame,
    feature_names: Sequence[str],
) -> Dict[str, Any]:
    modes: Dict[str, Any] = {}
    for column in feature_names:
        if column not in dataset.columns:
            continue
        series = dataset[column].dropna()
        if series.empty:
            continue
        mode_values = series.mode(dropna=True)
        if not mode_values.empty:
            modes[column] = clean_scalar(mode_values.iloc[0])
    return modes


def compute_numeric_bounds(
    dataset: pd.DataFrame,
    numeric_columns: Sequence[str],
) -> Dict[str, Tuple[Optional[float], Optional[float]]]:
    bounds: Dict[str, Tuple[Optional[float], Optional[float]]] = {}
    for column in numeric_columns:
        if column not in dataset.columns:
            continue
        series = pd.to_numeric(dataset[column], errors='coerce').dropna()
        if series.empty:
            continue
        lower = clean_scalar(series.min())
        upper = clean_scalar(series.max())
        bounds[column] = (lower, upper)
    return bounds


def sanitize_categories(values: Sequence[Any]) -> List[str]:
    cleaned: List[str] = []
    for value in values:
        scalar = clean_scalar(value)
        if scalar is None:
            continue
        text = str(scalar).strip()
        if not text:
            continue
        cleaned.append(text)
    return cleaned


def extract_schema_from_preprocessor(
    preprocessor: ColumnTransformer,
    feature_names: Sequence[str],
) -> Tuple[List[str], List[str], Dict[str, Any], Dict[str, Any], Dict[str, List[str]]]:
    numeric_cols: List[str] = []
    categorical_cols: List[str] = []
    numeric_defaults: Dict[str, Any] = {}
    categorical_defaults: Dict[str, Any] = {}
    categorical_options: Dict[str, List[str]] = {}

    for _, transformer, cols in getattr(preprocessor, 'transformers_', []):
        if transformer in ('drop', None):
            continue
        column_list = normalize_columns(cols, feature_names)
        if not column_list:
            continue

        if transformer == 'passthrough':
            numeric_cols.extend(column_list)
            continue

        imputer = extract_step(transformer, SimpleImputer)
        encoder = extract_step(transformer, OneHotEncoder)

        if encoder is not None:
            categorical_cols.extend(column_list)
            categories = getattr(encoder, 'categories_', [])
            for idx, column in enumerate(column_list):
                options = categories[idx] if idx < len(categories) else []
                categorical_options[column] = sanitize_categories(options)
        else:
            numeric_cols.extend(column_list)

        if imputer is not None and hasattr(imputer, 'statistics_'):
            stats = getattr(imputer, 'statistics_', [])
            for idx, column in enumerate(column_list):
                value = stats[idx] if idx < len(stats) else None
                if encoder is not None:
                    categorical_defaults[column] = clean_scalar(value)
                else:
                    numeric_defaults[column] = clean_scalar(value)

    ordered_numeric = [col for col in feature_names if col in set(numeric_cols)]
    ordered_categorical = [col for col in feature_names if col in set(categorical_cols)]

    return ordered_numeric, ordered_categorical, numeric_defaults, categorical_defaults, categorical_options


def sanitize_numeric_default(value: Any) -> Tuple[float | int, float | int]:
    value = clean_scalar(value)
    if isinstance(value, bool):
        return int(value), 1
    if isinstance(value, (int, np.integer)):
        return int(value), 1
    if isinstance(value, (float, np.floating)):
        float_value = float(value)
        if math.isnan(float_value):
            return 0.0, 0.1
        if float_value.is_integer():
            return int(float_value), 1
        return float_value, 0.1
    try:
        converted = float(value) if value is not None else 0.0
        if converted.is_integer():
            return int(converted), 1
        return converted, 0.1
    except (TypeError, ValueError):
        return 0.0, 0.1


def sanitize_categorical_default(candidate: Any, options: List[str]) -> str:
    candidate_value = clean_scalar(candidate)
    if candidate_value is None:
        return options[0] if options else ''
    candidate_text = str(candidate_value)
    if options and candidate_text not in options:
        return options[0]
    return candidate_text


def get_field_label(column: str) -> str:
    return FIELD_LABELS.get(column, column)


def format_codebook_option(option: Dict[str, object]) -> str:
    if isinstance(option, dict):
        return str(option.get('label', option.get('value')))
    return str(option)


def coerce_codebook_value(raw_value: str, sample: Optional[Any]) -> Any:
    if sample is not None:
        sample_type = type(sample)
        is_numeric_like = False
        if sample_type in {int, float}:
            is_numeric_like = True
        else:
            try:
                is_numeric_like = np.issubdtype(sample_type, np.number)
            except TypeError:
                is_numeric_like = False
        if is_numeric_like:
            try:
                return sample_type(raw_value)
            except Exception:
                pass
    try:
        return int(raw_value)
    except ValueError:
        try:
            return float(raw_value)
        except ValueError:
            return raw_value


def build_codebook_options(
    column: str,
    categorical_choices: Dict[str, List[Any]],
) -> List[Dict[str, object]]:
    label_map = CODEBOOK_LABELS.get(column, {})
    observed_values = categorical_choices.get(column, [])
    sample_value = observed_values[0] if observed_values else None

    options_values: List[Any] = []
    seen_keys: set[str] = set()

    for value in observed_values:
        key = str(value)
        if key in seen_keys:
            continue
        seen_keys.add(key)
        options_values.append(value)

    for key_str in label_map.keys():
        if key_str in seen_keys:
            continue
        value = coerce_codebook_value(key_str, sample_value)
        key = str(value)
        if key in seen_keys:
            continue
        seen_keys.add(key)
        options_values.append(value)

    result: List[Dict[str, object]] = []
    for value in options_values:
        key = str(value)
        label_text = label_map.get(key)
        display_label = label_text if label_text else str(value)
        result.append({'value': value, 'label': display_label})

    return result


HIDDEN_FEATURES = {
    'Application order',
    'Curricular units 1st sem (credited)',
    'Curricular units 1st sem (enrolled)',
    'Curricular units 1st sem (evaluations)',
    'Curricular units 1st sem (without evaluations)',
    'Curricular units 2nd sem (credited)',
    'Curricular units 2nd sem (enrolled)',
    'Curricular units 2nd sem (evaluations)',
    'Curricular units 2nd sem (without evaluations)',
    'Daytime/evening attendance',
    'Displaced',
    "Father's occupation",
    'GDP',
    'Inflation rate',
    'Marital status',
    "Mother's occupation",
    "Mother's qualification",
    'Previous qualification',
}


CODEBOOK_LABELS: Dict[str, Dict[str, str]] = {
    'Application mode': {
        '1': 'ì¼ë°˜ ì „í˜• / êµ­ê°€ ê²½ìŸ ì…í•™ì‹œí—˜',
        '2': 'íŠ¹ìˆ˜ ì¿¼í„°',
        '6': 'ì™¸êµ­ì¸ í•™ìƒ ì „í˜•',
        '8': 'í¸ì…',
        '12': 'ì¬ì…í•™',
    },
    'Previous qualification': {
        '1': 'ê³ ë“±í•™êµ ì¡¸ì—…',
        '2': 'í•™ìœ„ ì·¨ë“ ì´ì „ (í•™ì‚¬)',
        '10': 'í•™ìœ„ ì·¨ë“ ì´í›„ (ì„ì‚¬)',
    },
    'Course': {
        '33': 'íšŒê³„',
        '171': 'ê´€ë¦¬',
        '8014': 'ì •ë³´ ì‹œìŠ¤í…œ',
        '9070': 'ì‚¬íšŒ ì„œë¹„ìŠ¤',
    },
    'Daytime/evening attendance': {
        '1': 'ì£¼ê°„',
        '0': 'ì•¼ê°„',
    },
    'Marital status': {
        '1': 'ë¯¸í˜¼',
        '2': 'ê¸°í˜¼',
        '3': 'ë³„ê±°/ì´í˜¼',
        '6': 'ì‚¬ë³„',
    },
    'Gender': {
        '1': 'ë‚¨ì„±',
        '0': 'ì—¬ì„±',
    },
    'Debtor': {
        '1': 'ì±„ë¬´ ìˆìŒ',
        '0': 'ì±„ë¬´ ì—†ìŒ',
    },
    'Tuition fees up to date': {
        '1': 'ë‚©ë¶€ ì™„ë£Œ',
        '0': 'ë¯¸ë‚©',
    },
    'Scholarship holder': {
        '1': 'ì¥í•™ê¸ˆ ìˆ˜í˜œ',
        '0': 'ì¥í•™ê¸ˆ ì—†ìŒ',
    },
}


FIELD_LABELS: Dict[str, str] = {
    'Application mode': 'ì§€ì› ìœ í˜•',
    'Gender': 'ì„±ë³„',
    'Debtor': 'ì±„ë¬´ ì—¬ë¶€',
    'Tuition fees up to date': 'ë“±ë¡ê¸ˆ ë‚©ë¶€ ì—¬ë¶€',
    'Scholarship holder': 'ì¥í•™ê¸ˆ ìˆ˜í˜œ ì—¬ë¶€',
    'Age at enrollment': 'ì…í•™ ì‹œ ë‚˜ì´',
    'Curricular units 1st sem (approved)': '1í•™ê¸° ì´ìˆ˜ í•™ì (ìŠ¹ì¸)',
    'Curricular units 1st sem (grade)': '1í•™ê¸° ì´ìˆ˜ í•™ì (ì„±ì )',
    'Curricular units 2nd sem (approved)': '2í•™ê¸° ì´ìˆ˜ í•™ì (ìŠ¹ì¸)',
    'Curricular units 2nd sem (grade)': '2í•™ê¸° ì´ìˆ˜ í•™ì (ì„±ì )',
    'Curricular units 1st sem (enrolled)': '1í•™ê¸° ìˆ˜ê°• í•™ì ',
    'Curricular units 2nd sem (enrolled)': '2í•™ê¸° ìˆ˜ê°• í•™ì ',
    'Curricular units 1st sem (evaluations)': '1í•™ê¸° í‰ê°€ íšŸìˆ˜',
    'Curricular units 2nd sem (evaluations)': '2í•™ê¸° í‰ê°€ íšŸìˆ˜',
    'Curricular units 1st sem (without evaluations)': '1í•™ê¸° í‰ê°€ ì œì™¸ í•™ì ',
    'Curricular units 2nd sem (without evaluations)': '2í•™ê¸° í‰ê°€ ì œì™¸ í•™ì ',
    'Curricular units 1st sem (credited)': '1í•™ê¸° í•™ì  ì¸ì • ìˆ˜',
    'Curricular units 2nd sem (credited)': '2í•™ê¸° í•™ì  ì¸ì • ìˆ˜',
    'Application order': 'ì§€ì› ìˆœìœ„',
    'Daytime/evening attendance': 'ì£¼ê°„/ì•¼ê°„ êµ¬ë¶„',
    'Displaced': 'ê±°ì£¼ ì´ì „ ì—¬ë¶€',
    "Father's occupation": 'ë¶€ ì§ì—…',
    'GDP': 'êµ­ë‚´ì´ìƒì‚°(GDP)',
    'Inflation rate': 'ë¬¼ê°€ìƒìŠ¹ë¥ ',
    'Marital status': 'ê²°í˜¼ ìƒíƒœ',
    "Mother's occupation": 'ëª¨ ì§ì—…',
    "Mother's qualification": 'ëª¨ í•™ë ¥',
    'Previous qualification': 'ì´ì „ í•™ë ¥',
}


def render_metric_card(column, label: str, value: str) -> None:
    column.markdown(
        f"""
        <div class="metric-wrapper">
            <div class="metric-label">{label}</div>
            <div class="metric-value">{value}</div>
        </div>
        """,
        unsafe_allow_html=True,
    )


@st.cache_resource(show_spinner=False)
def load_pipeline():
    if not MODEL_PATH.exists():
        raise FileNotFoundError('í•™ìŠµëœ ëª¨ë¸ íŒŒì¼(model_trained.pkl)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í•™ìŠµì„ ìˆ˜í–‰í•˜ì„¸ìš”.')
    return joblib.load(MODEL_PATH)


@st.cache_data(show_spinner=False)
def load_metadata():
    pipeline = load_pipeline()
    fitted_estimator = unwrap_estimator(pipeline)
    feature_names = resolve_feature_names(fitted_estimator)

    preprocessor = find_column_transformer(fitted_estimator)
    if preprocessor is not None:
        (
            numeric_cols,
            categorical_cols,
            numeric_defaults_raw,
            categorical_defaults_raw,
            categorical_options_raw,
        ) = extract_schema_from_preprocessor(preprocessor, feature_names)
    else:
        numeric_cols = feature_names
        categorical_cols = []
        numeric_defaults_raw = {}
        categorical_defaults_raw = {}
        categorical_options_raw = {}

    remaining = [
        col for col in feature_names if col not in set(numeric_cols) | set(categorical_cols)
    ]
    if remaining:
        numeric_cols = list(numeric_cols) + remaining

    dataset_modes: Dict[str, Any] = {}
    numeric_bounds: Dict[str, Tuple[Optional[float], Optional[float]]] = {}
    dataset_summary: Dict[str, Any] = {}
    if DATASET_PATH.exists():
        try:
            dataset_df = pd.read_csv(DATASET_PATH)
            dataset_modes = compute_feature_modes(dataset_df, feature_names)
            numeric_bounds = compute_numeric_bounds(dataset_df, numeric_cols)
            dataset_summary = {
                'row_count': int(len(dataset_df)),
                'feature_count': int(dataset_df.shape[1]),
            }
            if 'Target' in dataset_df.columns:
                target_counts_series = dataset_df['Target'].value_counts(dropna=False)
                target_counts: Dict[str, int] = {
                    str(index): int(count) for index, count in target_counts_series.items()
                }
                dataset_summary['target_counts'] = target_counts
                total_count = sum(target_counts.values())
                if total_count > 0:
                    dataset_summary['dropout_ratio'] = target_counts.get('Dropout', 0) / total_count
                    dataset_summary['graduate_ratio'] = target_counts.get('Graduate', 0) / total_count
        except Exception:
            dataset_modes = {}
            numeric_bounds = {}
            dataset_summary = {}

    auto_fill_defaults: Dict[str, Any] = {
        column: dataset_modes.get(column) for column in feature_names
    }

    numeric_defaults: Dict[str, Dict[str, float | int]] = {}
    for col in numeric_cols:
        default_candidate = auto_fill_defaults.get(col)
        if default_candidate is None:
            default_candidate = numeric_defaults_raw.get(col)
        value, step = sanitize_numeric_default(default_candidate)
        numeric_defaults[col] = {'value': value, 'step': step}
        auto_fill_defaults[col] = value

    categorical_defaults: Dict[str, str] = {}
    categorical_options: Dict[str, List[str]] = {}
    for col in categorical_cols:
        options = categorical_options_raw.get(col, [])
        categorical_options[col] = options
        default_candidate = auto_fill_defaults.get(col)
        if default_candidate is None:
            default_candidate = categorical_defaults_raw.get(col)
        categorical_defaults[col] = sanitize_categorical_default(default_candidate, options)
        auto_fill_defaults[col] = categorical_defaults[col]

    for col in feature_names:
        if auto_fill_defaults.get(col) is None:
            fallback = dataset_modes.get(col)
            auto_fill_defaults[col] = fallback if fallback is not None else ''

    return (
        feature_names,
        numeric_cols,
        categorical_cols,
        numeric_defaults,
        categorical_defaults,
        categorical_options,
        auto_fill_defaults,
        numeric_bounds,
        dataset_summary,
    )


st.set_page_config(page_title='í•™ìƒ ì´íƒˆ ì˜ˆì¸¡', layout='wide')

st.markdown(
    """
    <style>
    :root {
        --primary-color: #3b82f6;
        --accent-color: #0ea5e9;
    }
    [data-testid="stAppViewContainer"] {
        background: linear-gradient(135deg, #ffffff 0%, #f4f7fb 100%);
    }
    [data-testid="stSidebar"] > div:first-child {
        background: linear-gradient(180deg, #111827 0%, #1f2937 100%);
        color: #f9fafb;
    }
    [data-testid="stSidebar"] h1, [data-testid="stSidebar"] h2, [data-testid="stSidebar"] h3 {
        color: #f9fafb;
    }
    .hero-section {
        padding: 2.5rem 3rem;
        border-radius: 18px;
        background: linear-gradient(135deg, rgba(59,130,246,0.95), rgba(14,165,233,0.9));
        color: #ffffff;
        box-shadow: 0 18px 35px rgba(15, 23, 42, 0.18);
        margin-bottom: 1.5rem;
    }
    .hero-section h1 {
        margin: 0;
        font-size: 2.2rem;
        font-weight: 700;
    }
    .hero-section p {
        margin-top: 0.75rem;
        font-size: 1.05rem;
        opacity: 0.9;
    }
    .metric-wrapper {
        padding: 1.1rem 1.4rem;
        border-radius: 14px;
        background: rgba(255, 255, 255, 0.85);
        box-shadow: 0 12px 28px rgba(15, 23, 42, 0.12);
        border: 1px solid rgba(148, 163, 184, 0.25);
    }
    .metric-label {
        font-size: 0.8rem;
        text-transform: uppercase;
        color: #64748b;
        letter-spacing: 0.08em;
        margin-bottom: 0.35rem;
    }
    .metric-value {
        font-size: 1.45rem;
        font-weight: 600;
        color: #0f172a;
    }
    .result-card {
        background: #ffffff;
        border-radius: 16px;
        padding: 1.6rem;
        box-shadow: 0 18px 32px rgba(15, 23, 42, 0.16);
        border: 1px solid rgba(148, 163, 184, 0.25);
    }
    .result-card h3 {
        margin-top: 0;
        margin-bottom: 0.9rem;
        font-weight: 600;
    }
    .result-badge {
        display: inline-block;
        padding: 0.6rem 1.1rem;
        border-radius: 999px;
        background: rgba(59,130,246,0.12);
        color: #1d4ed8;
        font-weight: 600;
        margin-bottom: 0.8rem;
    }
    .prob-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(160px, 1fr));
        gap: 1rem;
        margin-top: 1rem;
    }
    .prob-box {
        padding: 0.9rem 1.1rem;
        border-radius: 12px;
        background: rgba(241,245,249,0.7);
    }
    .prob-label {
        font-size: 0.85rem;
        color: #475569;
        font-weight: 500;
        margin-bottom: 0.25rem;
    }
    .prob-value {
        font-size: 1.35rem;
        font-weight: 600;
        color: #0f172a;
    }
    .sidebar-tips {
        padding: 1rem 1.1rem;
        border-radius: 14px;
        background: rgba(15,23,42,0.35);
        border: 1px solid rgba(148,163,184,0.2);
    }
    .stTabs [role="tab"] {
        padding: 0.75rem 1.4rem;
        border-radius: 12px 12px 0 0;
        margin-right: 0.5rem;
        background-color: rgba(255,255,255,0.55);
        font-weight: 600;
    }
    .stTabs [role="tab"][aria-selected="true"] {
        background: #ffffff;
        box-shadow: 0 -6px 18px rgba(15, 23, 42, 0.12);
        border-bottom: 2px solid transparent;
    }
    .stButton > button {
        background: linear-gradient(135deg, var(--primary-color), var(--accent-color));
        border: none;
        color: #ffffff;
        padding: 0.7rem 1.8rem;
        border-radius: 999px;
        font-weight: 600;
        box-shadow: 0 12px 24px rgba(59, 130, 246, 0.25);
    }
    .stButton > button:hover {
        filter: brightness(1.05);
    }
    </style>
    """,
    unsafe_allow_html=True,
)

st.markdown(
    """
    <div class="hero-section">
        <h1>í•™ìƒ ì´íƒˆ(ì¡¸ì—… ì—¬ë¶€) ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ</h1>
        <p>í•™ìŠµëœ ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•™ìƒ ì •ë³´ë¥¼ ì…ë ¥í•˜ë©´ Dropout ìœ„í—˜ë„ë¥¼ ì˜ˆì¸¡í•˜ê³ 
        í•„ìš”í•œ í”¼ì²˜ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
    </div>
    """,
    unsafe_allow_html=True,
)

try:
    (
        feature_cols,
        numeric_cols,
        categorical_cols,
        numeric_defaults,
        categorical_defaults,
        categorical_options,
        auto_fill_defaults,
        numeric_bounds,
        dataset_summary,
    ) = load_metadata()
    pipeline = load_pipeline()
except Exception as exc:
    st.error(f'ëª¨ë¸ ë˜ëŠ” ë©”íƒ€ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}')
    st.stop()

display_numeric_cols = [col for col in numeric_cols if col not in HIDDEN_FEATURES]
display_categorical_cols = [col for col in categorical_cols if col not in HIDDEN_FEATURES]

auto_fill_values: Dict[str, Any] = {}
for col in numeric_cols:
    default_config = numeric_defaults.get(col, {'value': 0.0})
    auto_fill_values[col] = default_config.get('value')
for col in categorical_cols:
    auto_fill_values[col] = categorical_defaults.get(col)
for col in feature_cols:
    if col not in auto_fill_values:
        auto_fill_values[col] = auto_fill_defaults.get(col)

feature_overview_rows: List[Dict[str, Any]] = []
for column in feature_cols:
    if column in numeric_cols:
        feature_type = 'ìˆ«ìí˜•'
    elif column in categorical_cols:
        feature_type = 'ë²”ì£¼í˜•'
    else:
        feature_type = 'ê¸°íƒ€'
    preview_value = auto_fill_values.get(column)
    feature_overview_rows.append(
        {
            'í”¼ì²˜': column,
            'í•œê¸€ ë¼ë²¨': get_field_label(column),
            'ìœ í˜•': feature_type,
            'ê¸°ë³¸ê°’ ë¯¸ë¦¬ë³´ê¸°': '' if preview_value is None else preview_value,
        }
    )
feature_overview_df = pd.DataFrame(feature_overview_rows)

codebook_options_map: Dict[str, List[Dict[str, object]]] = {}
for column in CODEBOOK_LABELS:
    if column not in feature_cols or column in HIDDEN_FEATURES:
        continue
    options = build_codebook_options(column, categorical_options)
    if options:
        codebook_options_map[column] = options

codebook_display_cols = list(codebook_options_map.keys())
display_numeric_cols = [col for col in display_numeric_cols if col not in codebook_display_cols]
display_categorical_cols = [col for col in display_categorical_cols if col not in codebook_display_cols]

with st.sidebar:
    st.markdown('## Quick Guide')
    st.markdown(
        """
        <div class="sidebar-tips">
            <ul style="list-style-type:none; padding-left:0; margin:0;">
                <li>âœ… ê¸°ë³¸ê°’ì€ í•™ìŠµ ë°ì´í„°ì˜ ìµœë¹ˆê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.</li>
                <li>ğŸ”¢ ìˆ«ìí˜• ì…ë ¥ì€ placeholderë¡œ ìµœì†Œ/ìµœëŒ€ ë²”ìœ„ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
                <li>ğŸ§¾ ë²”ì£¼í˜•ì€ ì½”ë“œë¶ ë¼ë²¨ì„ ë°”íƒ•ìœ¼ë¡œ ì„ íƒí•˜ê±°ë‚˜ ì§ì ‘ ì…ë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
                <li>ğŸš€ ì„¤ì • í›„ <strong>ì˜ˆì¸¡ ì‹¤í–‰</strong>ì„ ëˆŒëŸ¬ ê²°ê³¼ì™€ í™•ë¥ ì„ í™•ì¸í•˜ì„¸ìš”.</li>
            </ul>
        </div>
        """,
        unsafe_allow_html=True,
    )
    st.caption('ì…ë ¥ í•„ë“œëŠ” í•™ìŠµ íŒŒì´í”„ë¼ì¸ ìŠ¤í‚¤ë§ˆì™€ ë™ê¸°í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.')

if dataset_summary:
    st.markdown('### ë°ì´í„° í•œëˆˆì— ë³´ê¸°')
    metric_cols = st.columns(4)
    total_records = int(dataset_summary.get('row_count', 0))
    feature_count = int(dataset_summary.get('feature_count', 0))
    target_counts = dataset_summary.get('target_counts', {}) or {}
    total_target_count = sum(target_counts.values()) if target_counts else 0
    dropout_ratio = dataset_summary.get('dropout_ratio')
    graduate_ratio = dataset_summary.get('graduate_ratio')

    render_metric_card(metric_cols[0], 'ë°ì´í„° ìƒ˜í”Œ ìˆ˜', f"{total_records:,}")
    render_metric_card(metric_cols[1], 'ì‚¬ìš© í”¼ì²˜ ìˆ˜', str(feature_count))
    dropout_display = f"{dropout_ratio * 100:.1f}%" if dropout_ratio is not None else '--'
    render_metric_card(metric_cols[2], 'Dropout ë¹„ìœ¨', dropout_display)
    if graduate_ratio is not None:
        render_metric_card(metric_cols[3], 'Graduate ë¹„ìœ¨', f"{graduate_ratio * 100:.1f}%")
    elif total_target_count > 0 and target_counts:
        top_label = max(target_counts, key=target_counts.get)
        top_share = target_counts[top_label] / total_target_count
        render_metric_card(metric_cols[3], f'ìµœë‹¤ í´ë˜ìŠ¤ ({top_label})', f"{top_share * 100:.1f}%")
    else:
        render_metric_card(metric_cols[3], 'Graduate ë¹„ìœ¨', '--')
    st.markdown('')
else:
    st.warning('dataset.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° í†µê³„ë¥¼ í‘œì‹œí•˜ë ¤ë©´ íŒŒì¼ì„ ì¤€ë¹„í•˜ì„¸ìš”.')

tab_predict, tab_feature, tab_insight = st.tabs(['ì˜ˆì¸¡ ì‹¤í–‰', 'í”¼ì²˜ ê°€ì´ë“œ', 'ë°ì´í„° ì¸ì‚¬ì´íŠ¸'])

with tab_predict:
    st.markdown('#### ì˜ˆì¸¡ ì…ë ¥')
    st.caption('ìµœë¹ˆê°’ìœ¼ë¡œ ì±„ì›Œì§„ ê¸°ë³¸ ì…ë ¥ì„ ê²€í† í•˜ê³  í•„ìš”í•œ í•­ëª©ë§Œ ìˆ˜ì •í•œ ë’¤ ì˜ˆì¸¡ì„ ì‹¤í–‰í•˜ì„¸ìš”.')

    with st.form('prediction_form'):
        input_data: Dict[str, Any] = {}

        if codebook_display_cols:
            st.markdown('##### ì½”ë“œë¶ ê¸°ë°˜ ì£¼ìš” í•­ëª©')
            st.caption('ê³µì‹ ì½”ë“œ ë¼ë²¨ì„ ì°¸ê³ í•˜ì—¬ ë¹ ë¥´ê²Œ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.')
            codebook_layout = st.columns(max(1, min(len(codebook_display_cols), 3)))
            for idx, column in enumerate(codebook_display_cols):
                options = codebook_options_map.get(column, [])
                if not options:
                    continue
                default_value = auto_fill_values.get(column)
                default_index = 0
                if default_value is not None:
                    for opt_idx, option in enumerate(options):
                        if str(option['value']) == str(default_value):
                            default_index = opt_idx
                            break
                with codebook_layout[idx % len(codebook_layout)]:
                    selection = st.selectbox(
                        get_field_label(column),
                        options,
                        index=default_index,
                        format_func=format_codebook_option,
                    )
                input_data[column] = selection['value']

        if display_numeric_cols:
            st.markdown('---')
            st.markdown('##### ìˆ«ìí˜• í”¼ì²˜')
            numeric_layout = st.columns(max(1, min(len(display_numeric_cols), 3)))
            for idx, column in enumerate(display_numeric_cols):
                default_config = numeric_defaults.get(column, {'value': 0.0, 'step': 0.1})
                default_value = default_config['value']
                step_value = default_config['step']
                placeholder_text = None
                min_max = numeric_bounds.get(column)
                if min_max is not None:
                    lower, upper = min_max
                    if lower is not None and upper is not None:
                        try:
                            lower_int = int(float(lower))
                            upper_int = int(float(upper))
                            placeholder_text = f"{lower_int} ~ {upper_int}"
                        except (TypeError, ValueError):
                            placeholder_text = None
                with numeric_layout[idx % len(numeric_layout)]:
                    number_kwargs: Dict[str, Any] = {
                        'label': get_field_label(column),
                        'value': default_value,
                        'step': step_value,
                    }
                    if placeholder_text is not None:
                        number_kwargs['placeholder'] = placeholder_text
                    value = st.number_input(**number_kwargs)
                input_data[column] = value

        if display_categorical_cols:
            st.markdown('---')
            st.markdown('##### ë²”ì£¼í˜• í”¼ì²˜')
            categorical_layout = st.columns(max(1, min(len(display_categorical_cols), 2)))
            for idx, column in enumerate(display_categorical_cols):
                options = categorical_options.get(column, [])
                default_option = categorical_defaults.get(column, options[0] if options else '')
                with categorical_layout[idx % len(categorical_layout)]:
                    if options:
                        try:
                            default_index = options.index(default_option)
                        except ValueError:
                            default_index = 0
                        selection = st.selectbox(
                            get_field_label(column),
                            options,
                            index=default_index,
                        )
                    else:
                        selection = st.text_input(get_field_label(column), value=default_option)
                input_data[column] = selection

        other_columns = [
            col for col in feature_cols if col not in set(numeric_cols) | set(categorical_cols)
        ]
        if other_columns:
            st.markdown('---')
            st.markdown('##### ê¸°íƒ€ í”¼ì²˜')
            for column in other_columns:
                default_text = auto_fill_values.get(column)
                if default_text is None:
                    default_text = ''
                else:
                    default_text = str(default_text)
                input_data[column] = st.text_input(get_field_label(column), value=default_text)

        for hidden_feature in HIDDEN_FEATURES:
            if hidden_feature in feature_cols and hidden_feature not in input_data:
                input_data[hidden_feature] = auto_fill_values.get(hidden_feature)

        submitted = st.form_submit_button('ì˜ˆì¸¡ ì‹¤í–‰', use_container_width=True)

    if submitted:
        try:
            for column in feature_cols:
                input_data.setdefault(column, None)
            input_df = pd.DataFrame([input_data], columns=feature_cols)

            if not hasattr(pipeline, 'predict'):
                raise AttributeError('ë¡œë”©ëœ ê°ì²´ëŠ” ì˜ˆì¸¡ ê¸°ëŠ¥ì„ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.')

            prediction = pipeline.predict(input_df)[0]
            dropout_prob = graduate_prob = None
            if hasattr(pipeline, 'predict_proba'):
                probabilities = pipeline.predict_proba(input_df)[0]
                dropout_prob = float(probabilities[0])
                graduate_prob = float(probabilities[1])

            st.success('ì˜ˆì¸¡ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.')
            badge_text = 'Dropout' if prediction == 0 else 'Graduate'
            description_text = (
                'í•™ìƒì˜ ì¤‘ë„ ì´íƒˆ ê°€ëŠ¥ì„±ì´ ë” ë†’ê²Œ ì˜ˆì¸¡ë˜ì—ˆìŠµë‹ˆë‹¤.'
                if prediction == 0
                else 'í•™ìƒì´ ì¡¸ì—…í•  ê°€ëŠ¥ì„±ì´ ë” ë†’ê²Œ ì˜ˆì¸¡ë˜ì—ˆìŠµë‹ˆë‹¤.'
            )
            prob_section = ''
            if dropout_prob is not None and graduate_prob is not None:
                prob_section = (
                    '<div class="prob-grid">'
                    '<div class="prob-box">'
                    '<div class="prob-label">Dropout í™•ë¥ </div>'
                    f'<div class="prob-value">{dropout_prob * 100:.2f}%</div>'
                    '</div>'
                    '<div class="prob-box">'
                    '<div class="prob-label">Graduate í™•ë¥ </div>'
                    f'<div class="prob-value">{graduate_prob * 100:.2f}%</div>'
                    '</div>'
                    '</div>'
                )

            st.markdown(
                f"""
                <div class="result-card">
                    <h3>ì˜ˆì¸¡ ë¦¬í¬íŠ¸</h3>
                    <span class="result-badge">{badge_text}</span>
                    <p style="margin:0; color:#475569;">{description_text}</p>
                    {prob_section}
                </div>
                """,
                unsafe_allow_html=True,
            )

            with st.expander('ì…ë ¥ ê°’ ìƒì„¸ ë³´ê¸°', expanded=False):
                st.json(json.dumps(input_data, ensure_ascii=False, indent=2))
        except Exception as exc:
            st.error(f'ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}')
    else:
        st.info('ì˜ˆì¸¡ì„ í™•ì¸í•˜ë ¤ë©´ ì •ë³´ë¥¼ ì…ë ¥í•œ ë’¤ ì˜ˆì¸¡ ì‹¤í–‰ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì£¼ì„¸ìš”.')

with tab_feature:
    st.markdown('#### í”¼ì²˜ ìš”ì•½')
    if not feature_overview_df.empty:
        st.dataframe(
            feature_overview_df.sort_values(by='í”¼ì²˜'),
            use_container_width=True,
            hide_index=True,
        )
    else:
        st.info('í”¼ì²˜ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.')

    if codebook_display_cols:
        with st.expander('ì½”ë“œë¶ ë¼ë²¨ ë§¤í•‘', expanded=False):
            for column in codebook_display_cols:
                options = codebook_options_map.get(column, [])
                if not options:
                    continue
                st.markdown(f"**{get_field_label(column)} ({column})**")
                st.dataframe(pd.DataFrame(options), use_container_width=True, hide_index=True)

    visible_categorical = [
        col for col in categorical_cols if col not in HIDDEN_FEATURES and col not in codebook_display_cols
    ]
    if visible_categorical:
        with st.expander('ë²”ì£¼í˜• í”¼ì²˜ ì„ íƒì§€', expanded=False):
            for column in visible_categorical:
                options = categorical_options.get(column, [])
                if not options:
                    continue
                st.markdown(f"**{get_field_label(column)} ({column})**")
                st.write(', '.join(str(opt) for opt in options))

    hidden_columns = sorted(set(feature_cols).intersection(HIDDEN_FEATURES))
    if hidden_columns:
        st.caption('í™”ë©´ì—ì„œ ìˆ¨ê¹€ ì²˜ë¦¬ëœ í”¼ì²˜: ' + ', '.join(hidden_columns))

with tab_insight:
    st.markdown('#### ë°ì´í„° ì¸ì‚¬ì´íŠ¸')
    if dataset_summary:
        target_counts = dataset_summary.get('target_counts', {}) or {}
        if target_counts:
            st.markdown('##### Target ë¶„í¬')
            target_df = pd.DataFrame(
                {
                    'Target': list(target_counts.keys()),
                    'Count': [int(value) for value in target_counts.values()],
                }
            ).set_index('Target')
            st.bar_chart(target_df)

        numeric_range_rows: List[Dict[str, Any]] = []
        for column, bounds in numeric_bounds.items():
            if column in HIDDEN_FEATURES:
                continue
            lower, upper = bounds
            lower_display: Any = ''
            upper_display: Any = ''
            if lower is not None:
                try:
                    lower_float = float(lower)
                    lower_display = int(lower_float) if lower_float.is_integer() else round(lower_float, 2)
                except (TypeError, ValueError):
                    lower_display = lower
            if upper is not None:
                try:
                    upper_float = float(upper)
                    upper_display = int(upper_float) if upper_float.is_integer() else round(upper_float, 2)
                except (TypeError, ValueError):
                    upper_display = upper
            numeric_range_rows.append(
                {
                    'í”¼ì²˜': column,
                    'ìµœì†Œê°’': lower_display,
                    'ìµœëŒ€ê°’': upper_display,
                }
            )

        if numeric_range_rows:
            with st.expander('ìˆ«ìí˜• í”¼ì²˜ ë²”ìœ„', expanded=False):
                range_df = pd.DataFrame(numeric_range_rows).sort_values(by='í”¼ì²˜')
                st.dataframe(range_df, use_container_width=True, hide_index=True)

        st.caption('ë²”ìœ„ì™€ í†µê³„ëŠ” dataset.csv ê¸°ì¤€ì…ë‹ˆë‹¤.')
    else:
        st.warning('dataset.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ì¸ì‚¬ì´íŠ¸ë¥¼ í‘œì‹œí•˜ë ¤ë©´ íŒŒì¼ì„ ì¤€ë¹„í•˜ì„¸ìš”.')
